{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Summarize Youtube video lecture \n",
    "- Summarize Youtube's script by chapter creater configured. \n",
    "  - Create `markdown_note.md` with script and summary.\n",
    "- Use [youtube-transcript-api](https://pypi.org/project/youtube-transcript-api/), [langchain](https://github.com/hwchase17/langchain), and [OpenAI](https://github.com/openai/openai-python) package. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[33mWarning:\u001b[0m ffmpeg 6.0 is already installed and up-to-date.\n",
      "To reinstall 6.0, run:\n",
      "  brew reinstall ffmpeg\n",
      "Requirement already satisfied: youtube-transcript-api==0.6.1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: openai==0.27.8 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.27.8)\n",
      "Requirement already satisfied: langchain==0.0.154 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.0.154)\n",
      "Requirement already satisfied: openai-whisper==20230314 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (20230314)\n",
      "Requirement already satisfied: yt-dlp==2023.7.6 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2023.7.6)\n",
      "Requirement already satisfied: pydub==0.25.1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.25.1)\n",
      "Requirement already satisfied: requests in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from youtube-transcript-api==0.6.1->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from openai==0.27.8->-r requirements.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from openai==0.27.8->-r requirements.txt (line 3)) (3.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>1.4 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (2.0.16)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (0.5.8)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (1.24.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (1.10.9)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from langchain==0.0.154->-r requirements.txt (line 4)) (8.2.2)\n",
      "Requirement already satisfied: numba in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from openai-whisper==20230314->-r requirements.txt (line 5)) (0.57.1)\n",
      "Requirement already satisfied: torch in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from openai-whisper==20230314->-r requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: more-itertools in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from openai-whisper==20230314->-r requirements.txt (line 5)) (9.1.0)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from openai-whisper==20230314->-r requirements.txt (line 5)) (0.3.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from openai-whisper==20230314->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: mutagen in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from yt-dlp==2023.7.6->-r requirements.txt (line 6)) (1.46.0)\n",
      "Requirement already satisfied: pycryptodomex in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from yt-dlp==2023.7.6->-r requirements.txt (line 6)) (3.18.0)\n",
      "Requirement already satisfied: websockets in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from yt-dlp==2023.7.6->-r requirements.txt (line 6)) (11.0.3)\n",
      "Requirement already satisfied: certifi in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from yt-dlp==2023.7.6->-r requirements.txt (line 6)) (2023.5.7)\n",
      "Requirement already satisfied: brotli in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from yt-dlp==2023.7.6->-r requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: future in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314->-r requirements.txt (line 5)) (0.18.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from tiktoken==0.3.1->openai-whisper==20230314->-r requirements.txt (line 5)) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 3)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.154->-r requirements.txt (line 4)) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.154->-r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.154->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from pydantic<2,>=1->langchain==0.0.154->-r requirements.txt (line 4)) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from requests->youtube-transcript-api==0.6.1->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from requests->youtube-transcript-api==0.6.1->-r requirements.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from numba->openai-whisper==20230314->-r requirements.txt (line 5)) (0.40.1)\n",
      "Requirement already satisfied: filelock in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 5)) (3.12.2)\n",
      "Requirement already satisfied: sympy in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 5)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from torch->openai-whisper==20230314->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.154->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.154->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from jinja2->torch->openai-whisper==20230314->-r requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jinhoyoo/.pyenv/versions/venvAI/lib/python3.11/site-packages (from sympy->torch->openai-whisper==20230314->-r requirements.txt (line 5)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install libav and ffmpeg. \n",
    "! brew install ffmpeg \n",
    "\n",
    "# For linux (aptitude)\n",
    "# apt-get install libav-tools libavcodec-extra ffmpeg\n",
    "\n",
    "# install package \n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube video ID\n",
    "youtube_video_id=\"esr-1s91_9A\"\n",
    "\n",
    "# Language of subscription \n",
    "language = \"ko\"\n",
    "\n",
    "# LLM: Recommended parameters for my testing. \n",
    "max_token = 3000\n",
    "model = \"gpt-3.5-turbo\"\n",
    "chunk_size = 700\n",
    "chunk_overlap = 30\n",
    "\n",
    "# Officially no way to get chapter automatically, \n",
    "# so copy and paste the time stamp and chapter in description of Youtube video.\n",
    "\n",
    "chapter_part_in_description = \"\"\"\n",
    "1:12 질서자유주의와 사회적 시장경제\n",
    "3:49 실존철학의 메시지\n",
    "6:32 독일 기본법(헌법)과 대한민국 헌법의 정신\n",
    "18:58 우리는 어떻게 살아가고 있는가?\n",
    "23:54 우리는 앞으로 어떻게 살아야 하는가?\n",
    "28:56 피라미드형 계급구조 vs. 네트워크형 수평구조\n",
    "32:56 의사결정은 반드시 합의를 거친다 (consensus)\n",
    "45:54 대중의 지혜와 집단어리석음\n",
    "50:10 ‘게르만 모형’의 공동결정법과 ‘일하는 방식’\n",
    "54:55 아메리칸 드림에서 유러피언 드림으로\n",
    "1:02:03 자기의식과 변증법적 역사발전\n",
    "1:12:09 “우리는 다리를 놓으며 그 다리를 건너야 한다”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Officially no way to get chapter automatically, \n",
    "# so we need to parse the text in description and set up the dictionary \n",
    "# [ (time_in_sec, chapter_title) ]\n",
    "import re \n",
    "pattern = r'(\\d+(:\\d+){1,2})\\s(.+)'\n",
    "matches = re.findall(pattern, chapter_part_in_description)\n",
    "\n",
    "def time_to_seconds(time):\n",
    "    parts = time.split(':')\n",
    "    seconds = int(parts[-1])\n",
    "    minutes = int(parts[-2]) if len(parts) > 1 else 0\n",
    "    hours = int(parts[-3]) if len(parts) > 2 else 0\n",
    "    return hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "chapters = [(time_to_seconds(time), title.strip()) for time, _, title in matches]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build up note with chapter and script under each chapter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=esr-1s91_9A\n",
      "[youtube] esr-1s91_9A: Downloading webpage\n",
      "[youtube] esr-1s91_9A: Downloading ios player API JSON\n",
      "[youtube] esr-1s91_9A: Downloading android player API JSON\n",
      "[youtube] esr-1s91_9A: Downloading m3u8 information\n",
      "[info] esr-1s91_9A: Downloading 1 format(s): 140\n",
      "[download] audio/esr-1s91_9A.m4a has already been downloaded\n",
      "[download] 100% of   70.00MiB\n",
      "[ExtractAudio] Destination: audio/esr-1s91_9A.mp3\n",
      "Deleting original file audio/esr-1s91_9A.m4a (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "# Download youtube video and extract audio file. \n",
    "def download(video_id: str) -> str:\n",
    "    video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "    ydl_opts = {\n",
    "        'format': 'm4a/bestaudio/best',\n",
    "        'paths': {'home': 'audio/'},\n",
    "        'outtmpl': {'default': '%(id)s.%(ext)s'},\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "        }]\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        error_code = ydl.download([video_url])\n",
    "        if error_code != 0:\n",
    "            raise Exception('Failed to download video')\n",
    "\n",
    "    return f'audio/{video_id}.mp3'\n",
    "\n",
    "file_path = download(youtube_video_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split audio file\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio_data = AudioSegment.from_mp3(file_path)\n",
    "\n",
    "for i in range( len(chapters) ):\n",
    "    current_time_in_sec, current_title = chapters[i]\n",
    "    prev_time_in_sec, prev_title = chapters[i-1] if i>0 else (None, None)\n",
    "\n",
    "    current_time_in_ms = current_time_in_sec * 1000\n",
    "    prev_time_in_ms = prev_time_in_sec * 1000 if prev_time_in_sec is not None else 0\n",
    "\n",
    "\n",
    "    if prev_time_in_sec:\n",
    "        splitted_audio_data = audio_data[prev_time_in_ms:current_time_in_ms]\n",
    "    else:\n",
    "        splitted_audio_data = audio_data[:current_time_in_ms]\n",
    "\n",
    "    splitted_audio_data.export(f'audio/{i}.mp3' , format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 461M/461M [00:47<00:00, 10.3MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질서자유주의와 사회적 시장경제 is transcripting... \n",
      "\n",
      "실존철학의 메시지 is transcripting... \n",
      "\n",
      "독일 기본법(헌법)과 대한민국 헌법의 정신 is transcripting... \n",
      "\n",
      "우리는 어떻게 살아가고 있는가? is transcripting... \n",
      "\n",
      "우리는 앞으로 어떻게 살아야 하는가? is transcripting... \n",
      "\n",
      "피라미드형 계급구조 vs. 네트워크형 수평구조 is transcripting... \n",
      "\n",
      "의사결정은 반드시 합의를 거친다 (consensus) is transcripting... \n",
      "\n",
      "대중의 지혜와 집단어리석음 is transcripting... \n",
      "\n",
      "‘게르만 모형’의 공동결정법과 ‘일하는 방식’ is transcripting... \n",
      "\n",
      "아메리칸 드림에서 유러피언 드림으로 is transcripting... \n",
      "\n",
      "자기의식과 변증법적 역사발전 is transcripting... \n",
      "\n",
      "“우리는 다리를 놓으며 그 다리를 건너야 한다” is transcripting... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transcribe the text from audio files.\n",
    "import os\n",
    "import whisper\n",
    "\n",
    "\n",
    "# You can adjust the model used here. Model choice is typically a tradeoff between accuracy and speed.\n",
    "# All available models are located at https://github.com/openai/whisper/#available-models-and-languages.\n",
    "whisper_model = whisper.load_model(\"small\")\n",
    "\n",
    "script_by_chapter = []\n",
    "def transcribe(file_path: str) -> str:\n",
    "    # `fp16` defaults to `True`, which tells the model to attempt to run on GPU.\n",
    "    # For local demonstration purposes, we'll run this on the CPU by setting it to `False`.\n",
    "    transcription = whisper_model.transcribe(file_path, fp16=False)\n",
    "    return transcription['text']\n",
    "\n",
    "for i in range( len(chapters) ):\n",
    "    current_time_in_sec, current_title = chapters[i]\n",
    "    print( f'{current_title} is transcripting... \\n' )\n",
    "    audio_file_path = os.path.join( os.getcwd(), 'audio', f'{i}.mp3' )\n",
    "    transcript = transcribe(audio_file_path)\n",
    "    chapter_data = { \n",
    "                \"title\": current_title,\n",
    "                \"script\": transcript,\n",
    "                \"summary\" : \"\"\n",
    "                }\n",
    "    script_by_chapter.append(chapter_data)\n",
    "\n",
    "    # Save transcript file\n",
    "    text_file_folder_path = os.path.join( os.getcwd(), 'text')\n",
    "    if not os.path.exists( text_file_folder_path ):\n",
    "        os.makedirs(text_file_folder_path) \n",
    "\n",
    "    text_file = os.path.join(text_file_folder_path, f'{i}.txt')\n",
    "    with open( text_file, \"w\") as file:\n",
    "        file.write(transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Temporary save data into file \n",
    "import os \n",
    "import json \n",
    "\n",
    "with open( \"temp_script_by_chapter.json\", \"w\") as file:\n",
    "    file.write( json.dumps(script_by_chapter, indent=2, ensure_ascii=False) )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write note by summarizing contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setup OpenAI API key \n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def summarize_text_with_gpt3(text, max_token=3000, model=\"gpt-3.5-turbo\", languages=\"ko\"):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        네가 대학생이고 아래 문장을 요약해서 노트를 만든다고 하자. 최대한 저자의 의도와 문장을 살려서 \n",
    "        bulletin point를 붙여서 요약/정리해줘. 무언가 문장에 이상한 단어가 나오면 () 로 표시해줘.\n",
    "        ----------\n",
    "        {text}\n",
    "        \"\"\"\n",
    "    # prompt = f\"Summarize following text with bulletin points in Korean:\\n{text}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_token\n",
    "    )\n",
    "\n",
    "    corrected_text = response.choices[0].message.content\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    "    length_function = len\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 질서자유주의와 사회적 시장경제 is in-pro. \n",
      ".\n",
      "\n",
      "Chapter 실존철학의 메시지 is in-pro. \n",
      "..\n",
      "\n",
      "Chapter 독일 기본법(헌법)과 대한민국 헌법의 정신 is in-pro. \n",
      "..\n",
      "\n",
      "Chapter 우리는 어떻게 살아가고 있는가? is in-pro. \n"
     ]
    },
    {
     "ename": "ServiceUnavailableError",
     "evalue": "The server is overloaded or not ready yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m summarized_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m texts:\n\u001b[0;32m---> 21\u001b[0m     partial_summary \u001b[39m=\u001b[39m summarize_text_with_gpt3(t, max_token \u001b[39m=\u001b[39;49m max_token, model \u001b[39m=\u001b[39;49m model)\n\u001b[1;32m     22\u001b[0m     summarized_text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m partial_summary\n\u001b[1;32m     23\u001b[0m     \u001b[39mprint\u001b[39m( \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36msummarize_text_with_gpt3\u001b[0;34m(text, max_token, model, languages)\u001b[0m\n\u001b[1;32m     10\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[39m    네가 대학생이고 아래 문장을 요약해서 노트를 만든다고 하자. 최대한 저자의 의도와 문장을 살려서 \u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39m    bulletin point를 붙여서 요약/정리해줘. 무언가 문장에 이상한 단어가 나오면 () 로 표시해줘.\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39m    ----------\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39m# prompt = f\"Summarize following text with bulletin points in Korean:\\n{text}\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     18\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     19\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     20\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are a helpful assistant.\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m     21\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt}\n\u001b[1;32m     22\u001b[0m     ],\n\u001b[1;32m     23\u001b[0m     max_tokens\u001b[39m=\u001b[39;49mmax_token\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m corrected_text \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[1;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m corrected_text\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/envs/venvAI/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/envs/venvAI/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/envs/venvAI/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/envs/venvAI/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/envs/venvAI/lib/python3.11/site-packages/openai/api_requestor.py:743\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[39mreturn\u001b[39;00m OpenAIResponse(\u001b[39mNone\u001b[39;00m, rheaders)\n\u001b[1;32m    742\u001b[0m \u001b[39mif\u001b[39;00m rcode \u001b[39m==\u001b[39m \u001b[39m503\u001b[39m:\n\u001b[0;32m--> 743\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mServiceUnavailableError(\n\u001b[1;32m    744\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe server is overloaded or not ready yet.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    745\u001b[0m         rbody,\n\u001b[1;32m    746\u001b[0m         rcode,\n\u001b[1;32m    747\u001b[0m         headers\u001b[39m=\u001b[39mrheaders,\n\u001b[1;32m    748\u001b[0m     )\n\u001b[1;32m    749\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtext/plain\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m rheaders\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Create temporary folder to store note\n",
    "text_file_folder_path = os.path.join( os.getcwd(), 'note')\n",
    "if not os.path.exists( text_file_folder_path ):\n",
    "    os.makedirs(text_file_folder_path) \n",
    "\n",
    "# Summarize each chapter\n",
    "index = 0\n",
    "for c in script_by_chapter:\n",
    "    \n",
    "    # Split script\n",
    "    texts = text_splitter.split_text(c[\"script\"])\n",
    "\n",
    "    # Summarize the text \n",
    "    title = c[\"title\"]\n",
    "    print( f\"Chapter {title} is in-pro. \")\n",
    "    summarized_text = \"\"\n",
    "    for t in texts:\n",
    "        partial_summary = summarize_text_with_gpt3(t, max_token = max_token, model = model)\n",
    "        summarized_text += partial_summary\n",
    "        print( \".\", end=\"\")\n",
    "\n",
    "    c[\"summary\"] = summarized_text\n",
    "\n",
    "    # Save note into file\n",
    "    text_file = os.path.join(text_file_folder_path, f'{index}.txt')\n",
    "    with open( text_file, \"w\") as file:\n",
    "        file.write(summarized_text)\n",
    "    index += 1\n",
    "\n",
    "    print('\\n')\n",
    "    time.sleep(0.5) # Avoid the bad request error. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish markdown document\n",
    "\n",
    "Find `markdown_note.md`. This is the summarized note for this Youtube video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Remove temporary file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m os\u001b[39m.\u001b[39mremove(path, option)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Save file \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m( \u001b[39m\"\u001b[39m\u001b[39mscript_by_chapter.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Remove temporary data\n",
    "os.remove(\"temp_script_by_chapter.json\")\n",
    "\n",
    "# Save chapter data into file \n",
    "with open( \"script_by_chapter.json\", \"w\") as file:\n",
    "    file.write( json.dumps(script_by_chapter, indent=2, ensure_ascii=False) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_markdown_text = \"\"\n",
    "\n",
    "for c in script_by_chapter:\n",
    "    full_markdown_text += f\"# {c['title']} \\n\\n\"\n",
    "    full_markdown_text += f\"## Summary \\n\"\n",
    "    full_markdown_text += f\"{c['summary']} \\n\\n\"\n",
    "    full_markdown_text += f\"## Script \\n\\n\"\n",
    "    full_markdown_text += f\"{c['script']} \\n\"\n",
    "    full_markdown_text += \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write markdown document for note.\n",
    "with open( \"markdown_note.md\", \"w\") as file:\n",
    "    file.write(full_markdown_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
